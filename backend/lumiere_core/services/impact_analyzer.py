"""
Impact Analyzer Service

This service calculates the "blast radius" or impact scope for potential code changes
by analyzing the architectural graph and performing bidirectional traversals from seed files.
This is essential for the "Good First Issue" Scout feature to identify issues suitable for newcomers.
"""

import json
import pathlib
from typing import Dict, List, Set, Any, Optional
import logging

logger = logging.getLogger(__name__)


class ImpactAnalyzer:
    """
    Service to analyze the potential impact of code changes by calculating blast radius
    from seed files using the architectural graph generated by the Cartographer.
    """
    
    def __init__(self, cortex_directory: Optional[pathlib.Path] = None):
        """
        Initialize the Impact Analyzer.
        
        Args:
            cortex_directory: Optional path to the cortex directory. 
                            If None, will use default backend/cloned_repositories/
        """
        self.cortex_directory = cortex_directory or pathlib.Path("backend/cloned_repositories")
        
    def analyze_blast_radius(self, repo_id: str, seed_files: List[str], max_depth: int = 2) -> Dict[str, Any]:
        """
        Calculate the blast radius for a potential code change starting from seed files.
        
        Args:
            repo_id: Repository identifier
            seed_files: List of file paths to start the analysis from
            max_depth: Maximum depth for bidirectional traversal (default: 2)
            
        Returns:
            Dictionary containing blast radius analysis:
            {
                'blast_radius': int,           # Number of unique affected files
                'affected_nodes': List[str],   # List of affected file paths
                'depth': int,                  # Actual traversal depth used
                'seed_files': List[str],       # Original seed files
                'upstream_nodes': List[str],   # Dependencies (files that seed files depend on)
                'downstream_nodes': List[str], # Dependents (files that depend on seed files)
                'analysis_successful': bool    # Whether analysis completed successfully
            }
        """
        try:
            # Load the architectural graph
            architectural_graph = self._load_architectural_graph(repo_id)
            
            if not architectural_graph:
                logger.warning(f"No architectural graph found for repo {repo_id}")
                return {
                    'blast_radius': 0,
                    'affected_nodes': [],
                    'depth': 0,
                    'seed_files': seed_files,
                    'upstream_nodes': [],
                    'downstream_nodes': [],
                    'analysis_successful': False,
                    'error': 'No architectural graph available'
                }
            
            # Perform bidirectional graph traversal
            result = self._perform_bidirectional_traversal(
                architectural_graph, seed_files, max_depth
            )
            
            # Calculate blast radius
            all_affected = set(seed_files) | set(result['upstream_nodes']) | set(result['downstream_nodes'])
            
            return {
                'blast_radius': len(all_affected),
                'affected_nodes': sorted(list(all_affected)),
                'depth': max_depth,
                'seed_files': seed_files,
                'upstream_nodes': result['upstream_nodes'],
                'downstream_nodes': result['downstream_nodes'],
                'analysis_successful': True
            }
            
        except Exception as e:
            logger.error(f"Error analyzing blast radius for {repo_id}: {e}")
            return {
                'blast_radius': len(seed_files),  # Fallback to just seed files
                'affected_nodes': seed_files,
                'depth': 0,
                'seed_files': seed_files,
                'upstream_nodes': [],
                'downstream_nodes': [],
                'analysis_successful': False,
                'error': str(e)
            }
    
    def _load_architectural_graph(self, repo_id: str) -> Optional[Dict[str, Any]]:
        """
        Load the architectural graph from the Cortex file.
        
        Args:
            repo_id: Repository identifier
            
        Returns:
            Architectural graph dictionary or None if not found
        """
        cortex_file = self.cortex_directory / repo_id / "cortex.json"
        
        if not cortex_file.exists():
            logger.warning(f"Cortex file not found: {cortex_file}")
            return None
            
        try:
            with open(cortex_file, 'r', encoding='utf-8') as f:
                cortex_data = json.load(f)
                
            return cortex_data.get('architectural_graph')
            
        except Exception as e:
            logger.error(f"Error loading cortex file {cortex_file}: {e}")
            return None
    
    def _perform_bidirectional_traversal(
        self, 
        graph: Dict[str, Any], 
        seed_files: List[str], 
        max_depth: int
    ) -> Dict[str, List[str]]:
        """
        Perform bidirectional graph traversal from seed files.
        
        Args:
            graph: Architectural graph structure
            seed_files: Starting files for traversal
            max_depth: Maximum depth to traverse
            
        Returns:
            Dictionary with upstream and downstream nodes
        """
        # Extract nodes and edges from the graph
        nodes = set()
        dependencies = {}  # file -> list of files it depends on
        dependents = {}    # file -> list of files that depend on it
        
        # Parse the graph structure
        if 'nodes' in graph and 'edges' in graph:
            # Graph format: {"nodes": [...], "edges": [...]}
            for node in graph['nodes']:
                file_path = self._extract_file_path_from_node(node)
                if file_path:
                    nodes.add(file_path)
                    dependencies[file_path] = []
                    dependents[file_path] = []
            
            for edge in graph['edges']:
                source = self._extract_file_path_from_edge(edge, 'source')
                target = self._extract_file_path_from_edge(edge, 'target')
                
                if source and target:
                    # source depends on target
                    dependencies.setdefault(source, []).append(target)
                    # target is depended upon by source
                    dependents.setdefault(target, []).append(source)
                    
        elif isinstance(graph, dict):
            # Assume direct adjacency list format: {"file1": ["dep1", "dep2"], ...}
            for file_path, deps in graph.items():
                nodes.add(file_path)
                dependencies[file_path] = deps if isinstance(deps, list) else []
                
                # Build reverse dependencies
                for dep in dependencies[file_path]:
                    dependents.setdefault(dep, []).append(file_path)
        
        # Perform upstream traversal (dependencies)
        upstream_nodes = self._traverse_graph(dependencies, seed_files, max_depth)
        
        # Perform downstream traversal (dependents) 
        downstream_nodes = self._traverse_graph(dependents, seed_files, max_depth)
        
        return {
            'upstream_nodes': upstream_nodes,
            'downstream_nodes': downstream_nodes
        }
    
    def _extract_file_path_from_node(self, node: Any) -> Optional[str]:
        """Extract file path from a graph node."""
        if isinstance(node, str):
            return node
        elif isinstance(node, dict):
            # Try common keys
            for key in ['id', 'file_path', 'path', 'name']:
                if key in node:
                    return node[key]
        return None
    
    def _extract_file_path_from_edge(self, edge: Any, direction: str) -> Optional[str]:
        """Extract file path from a graph edge."""
        if isinstance(edge, dict):
            node_ref = edge.get(direction)
            if isinstance(node_ref, str):
                return node_ref
            elif isinstance(node_ref, dict):
                return self._extract_file_path_from_node(node_ref)
        return None
    
    def _traverse_graph(
        self, 
        adjacency_list: Dict[str, List[str]], 
        start_nodes: List[str], 
        max_depth: int
    ) -> List[str]:
        """
        Traverse the graph from start nodes up to max_depth.
        
        Args:
            adjacency_list: Graph adjacency list
            start_nodes: Starting nodes for traversal
            max_depth: Maximum depth to traverse
            
        Returns:
            List of visited nodes (excluding start nodes)
        """
        visited = set()
        queue = [(node, 0) for node in start_nodes if node in adjacency_list]
        
        while queue:
            current_node, depth = queue.pop(0)
            
            if current_node in visited or depth >= max_depth:
                continue
                
            visited.add(current_node)
            
            # Add neighbors to queue
            neighbors = adjacency_list.get(current_node, [])
            for neighbor in neighbors:
                if neighbor not in visited:
                    queue.append((neighbor, depth + 1))
        
        # Return all visited nodes except the original start nodes
        return [node for node in visited if node not in start_nodes]
    
    def calculate_impact_score(self, blast_radius: int, file_count: int = 100) -> float:
        """
        Calculate a normalized impact score based on blast radius.
        
        Args:
            blast_radius: Number of affected files
            file_count: Total files in repository (for normalization)
            
        Returns:
            Impact score between 0.0 and 1.0 (higher = more impact)
        """
        if file_count <= 0:
            return 0.0
            
        # Normalize blast radius by total file count
        normalized_radius = min(blast_radius / file_count, 1.0)
        
        # Apply logarithmic scaling to avoid penalizing medium-impact changes too heavily
        import math
        return math.sqrt(normalized_radius)
    
    def calculate_onboarding_suitability_score(self, blast_radius: int, max_suitable_radius: int = 100) -> float:
        """
        Calculate onboarding suitability score (inverse of impact).
        Lower blast radius = higher suitability for newcomers.
        
        Args:
            blast_radius: Number of affected files
            max_suitable_radius: Maximum blast radius considered suitable
            
        Returns:
            Suitability score between 0.0 and 100.0 (higher = more suitable)
        """
        if blast_radius <= 0:
            return 100.0
            
        # Invert the blast radius - smaller changes are more suitable
        clamped_radius = min(blast_radius, max_suitable_radius)
        suitability = 100.0 - (clamped_radius / max_suitable_radius * 100.0)
        
        return max(0.0, suitability)


# Convenience functions for external use
def analyze_blast_radius(repo_id: str, seed_files: List[str], max_depth: int = 2) -> Dict[str, Any]:
    """
    Convenience function to analyze blast radius.
    
    Args:
        repo_id: Repository identifier
        seed_files: List of file paths to start analysis from
        max_depth: Maximum traversal depth
        
    Returns:
        Blast radius analysis results
    """
    analyzer = ImpactAnalyzer()
    return analyzer.analyze_blast_radius(repo_id, seed_files, max_depth)


def calculate_onboarding_suitability(blast_radius: int) -> float:
    """
    Convenience function to calculate onboarding suitability score.
    
    Args:
        blast_radius: Number of affected files
        
    Returns:
        Suitability score (0-100, higher = more suitable for newcomers)
    """
    analyzer = ImpactAnalyzer()
    return analyzer.calculate_onboarding_suitability_score(blast_radius)